{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9478061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ee\n",
    "import numpy as np\n",
    "import time\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# initialize ee\n",
    "ee.Initialize()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e915216f",
   "metadata": {},
   "source": [
    "### Key User Input\n",
    "Here is the kernel where we include key parameters which define our downloads. These are the following:<br>\n",
    " - **shapefile_name**: This is the path to the shapefile which defines the spatial area we are interested in.<br>\n",
    " - **key**: This is the extension that all files will have attached to them to identify the files.<br>\n",
    " - **year**: The year of data we want to download. We download only a year to keep the data volumes low. <br>\n",
    " - **download_directory**: Where we want to place the downloaded data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc13f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile_name = '/media/DataShare/Alex/un_surinam/eo4sgs_inital_aoi.geojson'\n",
    "key = 'test_download'\n",
    "year = 2018\n",
    "download_directory = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12cfbb",
   "metadata": {},
   "source": [
    "We will be using the Google Earth Engine to to download the data. This is a huge repository of petabytes of data where we can cleanly aquire data for any given region within the timeframe available from each sensor. This is done in the python API by constructing a call to their API, filtering the dataset to the area and time we want and then we can export this 'Image collection' to a google 'asset'. To view all the available dataset available with Google Earth Engine, see this link: https://developers.google.com/earth-engine/datasets/catalog <br><br>\n",
    "To learn more about how to use the Google Earth Engine, please refere to the following:\n",
    "https://developers.google.com/earth-engine/tutorials/community/intro-to-python-api <br><br>\n",
    "Below is where we construct the call to the sensor ( Sentinel 1 https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S1_GRD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c56bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifiy the product we are interested in. This is unique to each sensor\n",
    "# and found on each the product specification page\n",
    "product = 'COPERNICUS/S1_GRD'\n",
    "\n",
    "# setout how you want label this data. As we are using Sentinel 1 we can use\n",
    "# the following\n",
    "dataset_custom_tag = 'S1_GRD'\n",
    "\n",
    "# we can open the geojson with the 'json' toolbox\n",
    "geoj = json.load(open(shapefile_name, 'r'))\n",
    "# we then use this json to create a Google Earth Engine Geometry Object \n",
    "geometry = ee.Geometry.Polygon(geoj['features'][0]['geometry']['coordinates'][0])\n",
    "\n",
    "# to filter the time, we use strings with the following format\n",
    "# YYY-MM-DD\n",
    "start_date = '%s-01-01'%year\n",
    "end_date = '%s-12-31'%year\n",
    "\n",
    "# specificy the bands we want. These can be found here:\n",
    "# Construct the GEE collection\n",
    "bands = ['VH','VV','angle']\n",
    "resolutions = [10,10,10]\n",
    "        \n",
    "# create the Image Collection\n",
    "ee_collection = (ee.ImageCollection(product).\n",
    "                 filterBounds(geometry).\n",
    "                 filterDate(start_date, end_date).\n",
    "                 select(bands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5a794f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Image Aquisitions:\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "# you can interact with the immage collections with a few basic commands\n",
    "# but we dont need to do anything else to the Image Collection to download\n",
    "# the data. \n",
    "print ('Number of Image Aquisitions:')\n",
    "print (ee_collection.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8b7bee",
   "metadata": {},
   "source": [
    "To download the Image Collection, we need a two step process. Firstly we need to export the datasets to a Google Drive and then we can export from the Drive to the local machine, using gsutils. This works by individually exporting all data for each band to the Drive, which is a time consuming process as the Earth Engine acually does the processing in this stage for us. We wait in the 'while' loop until this prcoess is completed. We then use 'gsutils' which is a linux command line toolbox, which we call from python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183b56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S2 test_download 2018) 213s  - O4FXV57UEER2HDAL2XGBE22Wtest_download_B12 - READY // NIFA4L73TG6DLTPG42SHKMTMtest_download_B11 - READY // O5GN7NGKRS2W7XB5SOLH24NGtest_download_B8A - READY // BEECDUQSOAMXZ7IMTIKWAQZStest_download_B8 - READY // LBHOI7KK4CVHGAWGYHQQ5UJTtest_download_B7 - READY // 7F2MRZUORUNRNW7OGTHS64NTtest_download_B6 - READY // 7PUNX6VGPU2MK6EEPYI66RIWtest_download_B5 - READY // 2VUHXRQ2S4YOXF3QT73UZ5IOtest_download_B4 - READY // Z3SBJMHIFUJQDFQFIVFNC7VCtest_download_B3 - READY // DHYXQ7YPTVFVM3JJPLPH5ZLGtest_download_B2 - READY\r"
     ]
    }
   ],
   "source": [
    "# create a list to put the tasks in so we can check their progress\n",
    "tasks = []\n",
    "\n",
    "# loop throguh each Landsat 5 band and export them to the google drive\n",
    "for resolution, band in zip(resolutions, bands):\n",
    "    \n",
    "    # create a unique key to attach to the data     \n",
    "    unique_desc = f'{key}_{band}'\n",
    "    \n",
    "    # USER INPUT\n",
    "    # the user must use the following command to export the data\n",
    "    # https://developers.google.com/earth-engine/apidocs/export-image-todrive\n",
    "    \n",
    "    DRIVE_NAME = '#YOUR_DRIVE_HERE#'\n",
    "    \n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image = ee_collection.select(band).toBands(),\n",
    "        region = geometry,\n",
    "        description = unique_desc,\n",
    "        folder = DRIVE_NAME,\n",
    "        fileNamePrefix = '%s_%s_%s_%s'%(dataset_custom_tag, key, \n",
    "                                        year, band),\n",
    "        scale = resolution,\n",
    "        maxPixels = 1e13)\n",
    "    \n",
    "    tasks.append(task)\n",
    "\n",
    "for task in tasks:\n",
    "    task.start()\n",
    "\n",
    "# continue in this while loop until all the tasks are finished. Once\n",
    "# complete they will be sitting on the google bucket\n",
    "\n",
    "# record when we started waiting for the data\n",
    "start = time.time()\n",
    "\n",
    "while len([i.status()['state'] for i in tasks if i.status()['state'] == 'COMPLETED']) < len(bands):\n",
    "\n",
    "    # use the command line 'earthengine' package to find how our \n",
    "    # downloads are going\n",
    "    result = subprocess.run(['earthengine', 'task', 'list'], stdout=subprocess.PIPE)\n",
    "     # get information for the most recent tasks, which is what\n",
    "    # we are waiting for\n",
    "    output = str(result.stdout).replace('  Export.image  ','').split('\\\\n')[:10]\n",
    "    # format all this information\n",
    "    trimmed = [[i for i in j.split(' ') if len(i) > 0] for j in output]\n",
    "    prnt_lines = ['%s - %s'%(i[0],i[1]) for i in trimmed]\n",
    "\n",
    "    second_dif = str(int(time.time() - start))+'s'\n",
    "    second_dif_str_second = f\"{second_dif:<5}\"\n",
    "    second_dif_str = '(S1 %s %s) %s'%(key,year,second_dif_str_second)\n",
    "    prnt = '%s - %s // %s // %s // %s // %s // %s // %s // %s // %s // %s'%(second_dif_str,prnt_lines[0][2:],prnt_lines[1],prnt_lines[2],\n",
    "                                                    prnt_lines[3],prnt_lines[4],prnt_lines[5],prnt_lines[6],\n",
    "                                                   prnt_lines[7],prnt_lines[8],prnt_lines[9])\n",
    "\n",
    "    sys.stdout.write('%s\\r' % (prnt,))\n",
    "    sys.stdout.flush()\n",
    "    # there are four possible state of the task which will be printed out:\n",
    "    # READY\n",
    "    # RUNNING\n",
    "    # COMPLETED\n",
    "    # FAILED\n",
    "    \n",
    "\n",
    "print ('\\n')\n",
    "\n",
    "# once this is done, we use gsutils to move this data from the Drive to \n",
    "# your local machine. \n",
    "\n",
    "# check the output directory exists and create if needs be\n",
    "dest = os.path.join(download_directory)\n",
    "if os.path.isdir(dest) == False:\n",
    "    os.makedirs(dest)\n",
    "    \n",
    "# constrcut the command line call\n",
    "cmd = 'gsutil mv gs://%s/%s_%s_%s* %s/'%(DRIVE_NAME, dataset_custom_tag,\n",
    "                                         key, year, dest)\n",
    "\n",
    "print ('Starting data downloads:')\n",
    "# use python to call this command and move the data\n",
    "subprocess.call(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
